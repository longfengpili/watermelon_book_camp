{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量机\n",
    "支持向量机就是基于训练集D在样本空间找到一个划分超平面，并且使得样本集中所有的数据到这个超平面的距离最短，或者说最大化间隔。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM原始形式的推到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见的几何性质（欧式空间）\n",
    "![svm](./svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 法向量\n",
    "$$\n",
    "\\left\\{\\begin{array}{ll}{w^{T} x_{1}+b} & {=0} \\\\ {w^{T} x_{2}+b} & {=0} \\\\ {w^{T}\\left(x_{1}-x_{2}\\right)} & {=0}\\end{array}\\right.\n",
    "$$\n",
    "$${w}是法向量$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原点到平面的‘距离’\n",
    "$$\n",
    "\\left\\{\\begin{array}{ll}{w^{T} x_{1}+b} & {=0} \\\\ {\\lambda w^{T} \\frac{w}{\\|w\\|}+b} & {=0} \\\\ {\\text { offset }} & {=\\frac{-b}{\\|w\\|}}\\end{array}\\right.\n",
    "$$\n",
    "$$\\frac{-b}{\\|w\\|}是原点到平面的距离$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 由图可知，求距离，做垂直线（绿色的）\n",
    "\n",
    "$$\n",
    "x^{'} = \\lambda\\frac{w}{\\|w\\|}\\tag1\n",
    "$$  \n",
    "\n",
    "2. 代入${w}^{T}x_{1}+b =0$，得\n",
    "$$\\lambda {w}^{T} \\frac{w}{\\|w\\|}+b=0\\tag2$$\n",
    "3. ${w}^T{w}={\\|w\\|}^2$\n",
    "$$\\lambda{\\|w\\|} + b = 0\\tag3$$\n",
    "$$\\lambda=\\frac{-b}{\\|w\\|}\\tag4$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 点到平面的距离\n",
    "$$\n",
    "r=\\frac{\\left|w^{T} x+b\\right|}{\\|w\\|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r = {\\|\\frac{{w}^T}{\\|w\\|}x\\frac{w}{\\|w\\|}-\\frac{-b}{\\|w\\|}\\frac{w}{\\|w\\|}\\|}\n",
    "$$\n",
    "\n",
    "$$继续推导$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned} r &=\\left\\|\\frac{\\boldsymbol{w}^{T} \\boldsymbol{x}}{\\|\\boldsymbol{w}\\|^{2}} \\boldsymbol{w}-\\frac{-b}{\\|\\boldsymbol{w}\\|^{2}} \\boldsymbol{w}\\right\\| \\\\ &=\\left\\|\\frac{\\boldsymbol{w}^{T} \\boldsymbol{x}}{\\|\\boldsymbol{w}\\|^{2}}+\\frac{b}{\\|\\boldsymbol{w}\\|^{2}}\\right\\|\\|\\boldsymbol{w}\\| \\\\ &=\\frac{\\left\\|\\boldsymbol{w}^{T} \\boldsymbol{x}+b\\right\\|}{\\|\\boldsymbol{w}\\|} \\\\ &=\\frac{\\left|\\boldsymbol{w}^{T} \\boldsymbol{x}+b\\right|}{\\|\\boldsymbol{w}\\|} \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM原始形式的推导（核心是最大化间隔）\n",
    "![最大化间隔](./svm1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r=\\frac{\\left|w^{T} x+b\\right|}{\\|w\\|}\\tag1\n",
    "$$\n",
    "\n",
    "$$假设可以分开数据集，那么任意一点到平面的距离如下：（等价1式）$$\n",
    "\n",
    "$$\n",
    "r_{i}=\\frac{y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right)}{\\|\\boldsymbol{w}\\|}\\tag2\n",
    "$$\n",
    "$$那么最接近平面的距离$$\n",
    "$$d=\\min{(d^+,d^-)}$$\n",
    "$$\n",
    "d=\\min _{i} \\boldsymbol{y}_{i}\\left(\\frac{\\boldsymbol{w}^{T}}{\\|\\boldsymbol{w}\\|} \\boldsymbol{x}_{i}+\\frac{b}{\\|\\boldsymbol{w}\\|}\\right)\\tag3\n",
    "$$\n",
    "$$所有可能的距离中，最大的距离，是间隔的一半$$\n",
    "\n",
    "$$\n",
    "d^{*}=\\max _{w, b} \\min _{i} y_{i}\\left(\\frac{w^{T}}{\\|\\boldsymbol{w}\\|} \\boldsymbol{x}_{i}+\\frac{b}{\\|\\boldsymbol{w}\\|}\\right) \\tag4\n",
    "$$\n",
    "$$\n",
    "\\gamma=2 d^{*}=\\max _{w, b} \\min _{i} 2 \\times y_{i}\\left(\\frac{w^{T}}{\\|\\boldsymbol{w}\\|} \\boldsymbol{x}_{i}+\\frac{b}{\\|\\boldsymbol{w}\\|}\\right)\\tag5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma=2 d^{*}=\\max _{w, b} \\min _{i} 2 \\times y_{i}\\left(\\frac{w^{T}}{\\|\\boldsymbol{w}\\|} \\boldsymbol{x}_{i}+\\frac{b}{\\|\\boldsymbol{w}\\|}\\right)\\tag1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}{\\max _{\\boldsymbol{w}, b} 2 d} \\\\ {\\text { s.t. } \\boldsymbol{y}_{i}\\left(\\frac{\\boldsymbol{w}^{T}}{\\|\\boldsymbol{w}\\|} \\boldsymbol{x}_{i}+\\frac{b}{\\|\\boldsymbol{w}\\|}\\right) \\geq d \\text { for } \\boldsymbol{i}=1, \\ldots, m} \\\\ {d>0}\\end{array}\\tag2\n",
    "$$\n",
    ">  引入新的定义：函数间隔$\\hat{d}=\\|\\boldsymbol{w}\\| d$  \n",
    "\n",
    "$$\n",
    "\\begin{array}{l}{\\max _{\\boldsymbol{w}, b} \\frac{2 \\hat{d}}{\\|\\boldsymbol{w}\\|}} \\\\ {\\text { s.t. } \\boldsymbol{y}_{i}\\left(\\boldsymbol{w}^{T} \\boldsymbol{x}_{i}+b\\right) \\geq \\hat{d} \\text { for } \\boldsymbol{i}=1, \\ldots, N} \\\\ {\\hat{d}>0}\\end{array}\\tag3\n",
    "$$\n",
    "> 实际上，$\\hat{d}$取值并不影响最优化问题的解，故取$\\hat{d}=1$  \n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}{\\max _{\\boldsymbol{w}, b}} & {\\frac{2}{\\|\\boldsymbol{w}\\|}} \\\\ {\\text { s.t. }} & {\\boldsymbol{y}_{i}\\left(\\boldsymbol{w}^{T} \\boldsymbol{x}_{i}+b\\right) \\geq 1, \\quad i=1,2, \\ldots, m}\\end{array}\\tag4\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\min _{\\boldsymbol{w}, b} & \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2} \\\\ \\text { s.t. } & \\boldsymbol{y}_{i}\\left(\\boldsymbol{w}^{T} \\boldsymbol{x}_{i}+b\\right) \\geq 1, \\quad i=1,2, \\ldots, m \\end{aligned}\\tag5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要调节的参数有：C、kernel、degree、gamma、coef0。\n",
    "1. C：C-SVC的惩罚参数C，默认值是1.0\n",
    "\tC越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "2. kernel ：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’  \n",
    "　　0 – 线性：$\\left\\langle x, x^{\\prime}\\right\\rangle$   \n",
    "　　1 – 多项式：$\\left(\\gamma\\left\\langle x, x^{\\prime}\\right)+r\\right)^{d}$  \n",
    "　　2 – RBF函数：$\\exp \\left(-\\gamma\\left\\|x-x^{\\prime}\\right\\|^{2}\\right)$  \n",
    "　　3 –sigmoid：$\\left(\\tanh \\left(\\gamma\\left\\langle x, x^{\\prime}\\right\\rangle+ r\\right)\\right)$  \n",
    "3. degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "4. gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features\n",
    "5. coef0 ：核函数的常数项。对于‘poly’和 ‘sigmoid’有用。\n",
    "6. probability ：是否采用概率估计？.默认为False\n",
    "7. shrinking ：是否采用shrinking heuristic方法，默认为true\n",
    "8. tol ：停止训练的误差值大小，默认为1e-3\n",
    "9. cache_size ：核函数cache缓存大小，默认为200\n",
    "10. class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)\n",
    "11. verbose ：允许冗余输出？\n",
    "12. max_iter ：最大迭代次数。-1为无限制。\n",
    "13. decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None3\n",
    "14. random_state ：数据洗牌时的种子值，int值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T09:13:51.463159Z",
     "start_time": "2019-07-13T09:13:51.431246Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T09:14:36.772724Z",
     "start_time": "2019-07-13T09:14:36.763759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0  # SVM regularization parameter\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "        svm.LinearSVC(C=C, max_iter=10000),\n",
    "        svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "        svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = ('SVC with linear kernel',\n",
    "        'LinearSVC (linear kernel)',\n",
    "        'SVC with RBF kernel',\n",
    "        'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
